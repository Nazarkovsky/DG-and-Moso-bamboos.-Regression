# Generated by XGBoost for JMP
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost_jmp as xgb_jmp

#%%
mname = 'xgboost_DG_m16'
path = 'C:\Users\Michael Nazarkovsky\Documents\JMP\Self-Training\Bamboo\DG-Mosso by fibers\'
data = 'Bamboo=DG.csv'
yvar = {
   'fiber volume fraction %' : 'reg:squarederror'
}
xvar = ['Normalized Wall Thickness']
wvar = []
vvar = ['FoldA']
cvar = {
   'FoldA' : [1,2,3,4,5],
}
parms = {
   'max_depth' : 5,
   'subsample' : 0.645003247571672,
   'colsample_bytree' : 0.822184065600215,
   'min_child_weight' : 3.36672915126342,
   'alpha' : 0.572004021103452,
   'lambda' : 1.87108540261583,
   'learning_rate' : 0.090627486375438,
}
iter = 227

#%%
print('\n\nloading data')
df = pd.read_csv(path + data)
cats = list(cvar.keys())
df[cats] = df[cats].fillna('')
print(df.head(), df.shape)

#%%
print('\n\nfitting')
oof = xgb_jmp.fit(mname, path, df, yvar, xvar, wvar, vvar, cvar, parms, iter)
print(oof.head())
print(oof.shape)

#%%
print('\n\npredicting')
pred = xgb_jmp.predict(mname, path, df, yvar, xvar, vvar, cvar)
print(pred.head())
print(pred.shape)
ylist = list(yvar.keys())
sns.distplot(pred)
plt.title('Distribution of Predictions for ' + ylist[0] + ' ' + mname)
plt.show()
plt.gcf().clear()
print(pred.describe())
